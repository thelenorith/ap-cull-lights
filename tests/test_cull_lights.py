"""
Generated By: Cursor (Claude Sonnet 4.5)

Unit tests for ap_cull_lights.cull_lights module.
"""

import os
from pathlib import Path
from unittest.mock import MagicMock, patch

import pytest

from ap_cull_lights import cull_lights


class TestRejectImage:
    """Tests for reject_image function."""

    @patch("ap_common.move_file")
    def test_reject_image_moves_file(self, mock_move_file, tmp_path):
        """Test that reject_image moves file to reject directory."""
        source_dir = str(tmp_path / "source")
        reject_dir = str(tmp_path / "reject")
        test_file = tmp_path / "source" / "subdir" / "test.fits"

        # Create source file
        test_file.parent.mkdir(parents=True)
        test_file.write_text("test data")

        cull_lights.reject_image(
            filepath=str(test_file),
            reject_dir=reject_dir,
            source_dir=source_dir,
            dryrun=False,
            debug=False,
        )

        # Verify move_file was called
        mock_move_file.assert_called_once()
        call_args = mock_move_file.call_args
        assert str(test_file) in str(call_args[1]["from_file"])
        assert "reject" in str(call_args[1]["to_file"])
        assert "subdir" in str(call_args[1]["to_file"])

    @patch("ap_common.move_file")
    def test_reject_image_dryrun(self, mock_move_file, tmp_path, capsys):
        """Test that reject_image doesn't move file in dryrun mode."""
        source_dir = str(tmp_path / "source")
        reject_dir = str(tmp_path / "reject")
        test_file = tmp_path / "source" / "subdir" / "test.fits"

        test_file.parent.mkdir(parents=True)
        test_file.write_text("test data")

        cull_lights.reject_image(
            filepath=str(test_file),
            reject_dir=reject_dir,
            source_dir=source_dir,
            dryrun=True,
            debug=False,
        )

        # Verify move_file was NOT called
        mock_move_file.assert_not_called()

        # Verify output
        captured = capsys.readouterr()
        assert "REJECTED" in captured.out

    def test_reject_image_safety_check(self, tmp_path, monkeypatch):
        """Test that reject_image raises error for invalid destination."""
        source_dir = str(tmp_path / "source")
        reject_dir = str(tmp_path / "reject")
        test_file = tmp_path / "source" / "test.fits"
        test_file.parent.mkdir(parents=True)
        test_file.write_text("test data")

        # Create a mock that makes dest_resolved.relative_to(reject_path) raise ValueError
        # This simulates a path traversal scenario where dest is outside reject_dir
        original_relative_to = Path.relative_to
        call_tracker = {"dest_resolved_called": False}

        def mock_relative_to(self, other):
            # When relative_to is called on dest_resolved, make it fail
            if call_tracker["dest_resolved_called"]:
                raise ValueError("Path is not relative to other")
            return original_relative_to(self, other)

        # Track when we're checking the dest path
        original_resolve = Path.resolve

        def mock_resolve(self):
            result = original_resolve(self)
            # Mark that we've resolved the dest_path (contains reject_dir and test.fits)
            if "reject" in str(self) and "test.fits" in str(self):
                call_tracker["dest_resolved_called"] = True
            return result

        monkeypatch.setattr(Path, "relative_to", mock_relative_to)
        monkeypatch.setattr(Path, "resolve", mock_resolve)

        with pytest.raises(ValueError, match="invalid location"):
            cull_lights.reject_image(
                filepath=str(test_file),
                reject_dir=reject_dir,
                source_dir=source_dir,
                dryrun=False,
                debug=False,
            )


class TestCullLights:
    """Tests for cull_lights function."""

    @patch("ap_common.get_filtered_metadata")
    @patch("ap_cull_lights.cull_lights.reject_image")
    def test_cull_lights_processes_files(
        self, mock_reject, mock_get_metadata, tmp_path
    ):
        """Test that cull_lights processes files and rejects matching ones."""
        source_dir = str(tmp_path / "source")
        reject_dir = str(tmp_path / "reject")

        # Mock metadata
        mock_metadata = {
            "file1.fits": {
                "filename": str(tmp_path / "source" / "file1.fits"),
                "type": "LIGHT",
                "hfr": 3.0,  # Should be rejected (3.0 > 2.5)
            },
            "file2.fits": {
                "filename": str(tmp_path / "source" / "file2.fits"),
                "type": "LIGHT",
                "hfr": 1.5,  # Should pass (1.5 < 2.5)
            },
        }
        mock_get_metadata.return_value = mock_metadata

        # Mock input to auto-accept
        with patch("builtins.input", return_value="y"):
            cull_lights.cull_lights(
                source_dir=source_dir,
                reject_dir=reject_dir,
                max_hfr=2.5,
                max_rms=None,
                auto_yes_percent=-1,
                debug=False,
                dryrun=False,
            )

        # Verify get_filtered_metadata was called with correct filters
        mock_get_metadata.assert_called_once()
        call_kwargs = mock_get_metadata.call_args[1]
        assert call_kwargs["filters"]["type"] == "LIGHT"
        assert call_kwargs["recursive"] is True

        # Verify reject_image was called for file1 (but not file2)
        assert mock_reject.called

    @patch("ap_common.get_filtered_metadata")
    @patch("ap_cull_lights.cull_lights.reject_image")
    def test_cull_lights_auto_yes_percent(
        self, mock_reject, mock_get_metadata, tmp_path, capsys
    ):
        """Test that cull_lights auto-accepts when below threshold."""
        source_dir = str(tmp_path / "source")
        reject_dir = str(tmp_path / "reject")

        # Create 100 files, only 2 should be rejected (2% < 5%)
        mock_metadata = {}
        for i in range(100):
            hfr_value = 3.0 if i < 2 else 1.5  # First 2 rejected
            mock_metadata[f"file{i}.fits"] = {
                "filename": str(tmp_path / "source" / f"file{i}.fits"),
                "type": "LIGHT",
                "hfr": hfr_value,
            }
        mock_get_metadata.return_value = mock_metadata

        cull_lights.cull_lights(
            source_dir=source_dir,
            reject_dir=reject_dir,
            max_hfr=2.5,
            max_rms=None,
            auto_yes_percent=5.0,  # Auto-accept if < 5%
            debug=False,
            dryrun=False,
        )

        # Verify auto-accept message
        captured = capsys.readouterr()
        assert "automatic" in captured.out.lower()
        assert "y (automatic" in captured.out

    @patch("ap_common.get_filtered_metadata")
    @patch("ap_cull_lights.cull_lights.reject_image")
    def test_cull_lights_dryrun(self, mock_reject, mock_get_metadata, tmp_path, capsys):
        """Test that cull_lights works in dryrun mode."""
        source_dir = str(tmp_path / "source")
        reject_dir = str(tmp_path / "reject")

        mock_metadata = {
            "file1.fits": {
                "filename": str(tmp_path / "source" / "file1.fits"),
                "type": "LIGHT",
                "hfr": 3.0,
            }
        }
        mock_get_metadata.return_value = mock_metadata

        cull_lights.cull_lights(
            source_dir=source_dir,
            reject_dir=reject_dir,
            max_hfr=2.5,
            max_rms=None,
            auto_yes_percent=-1,
            debug=False,
            dryrun=True,
        )

        # Verify dryrun message
        captured = capsys.readouterr()
        assert "dryrun" in captured.out.lower()

    @patch("ap_common.get_filtered_metadata")
    @patch("ap_cull_lights.cull_lights.reject_image")
    def test_cull_lights_skips_files_matching_pattern(
        self, mock_reject, mock_get_metadata, tmp_path
    ):
        """Test that cull_lights skips files matching skip pattern."""
        import re

        source_dir = str(tmp_path / "source")
        reject_dir = str(tmp_path / "reject")

        # File in accept directory should be skipped
        accept_file = "subdir/accept/file1.fits"
        mock_metadata = {
            accept_file: {
                "filename": str(tmp_path / "source" / accept_file),
                "type": "LIGHT",
                "hfr": 3.0,  # Would be rejected, but matches skip pattern
            }
        }
        mock_get_metadata.return_value = mock_metadata

        skip_pattern = re.compile("accept")

        cull_lights.cull_lights(
            source_dir=source_dir,
            reject_dir=reject_dir,
            max_hfr=2.5,
            max_rms=None,
            auto_yes_percent=-1,
            skip_pattern=skip_pattern,
            debug=False,
            dryrun=False,
        )

        # File matching skip pattern should not be processed
        mock_reject.assert_not_called()


class TestMain:
    """Tests for main function."""

    @patch("ap_cull_lights.cull_lights.cull_lights")
    def test_main_calls_cull_lights(self, mock_cull):
        """Test that main function calls cull_lights with correct arguments."""
        with patch(
            "sys.argv",
            ["cull_lights.py", "/source", "/reject", "--max-hfr", "2.5"],
        ):
            cull_lights.main()

        mock_cull.assert_called_once()
        call_kwargs = mock_cull.call_args[1]
        assert call_kwargs["source_dir"] == "/source"
        assert call_kwargs["reject_dir"] == "/reject"
        assert call_kwargs["max_hfr"] == 2.5
        assert call_kwargs["max_rms"] is None

    @patch("ap_cull_lights.cull_lights.cull_lights")
    def test_main_with_max_rms(self, mock_cull):
        """Test main with --max-rms parameter."""
        with patch(
            "sys.argv",
            ["cull_lights.py", "/source", "/reject", "--max-rms", "2.0"],
        ):
            cull_lights.main()

        call_kwargs = mock_cull.call_args[1]
        assert call_kwargs["max_hfr"] is None
        assert call_kwargs["max_rms"] == 2.0

    @patch("ap_cull_lights.cull_lights.cull_lights")
    def test_main_with_both_params(self, mock_cull):
        """Test main with both --max-hfr and --max-rms."""
        with patch(
            "sys.argv",
            [
                "cull_lights.py",
                "/source",
                "/reject",
                "--max-hfr",
                "2.5",
                "--max-rms",
                "2.0",
            ],
        ):
            cull_lights.main()

        call_kwargs = mock_cull.call_args[1]
        assert call_kwargs["max_hfr"] == 2.5
        assert call_kwargs["max_rms"] == 2.0

    @patch("ap_cull_lights.cull_lights.cull_lights")
    def test_main_with_debug(self, mock_cull):
        """Test main with --debug flag."""
        with patch(
            "sys.argv",
            ["cull_lights.py", "/source", "/reject", "--max-hfr", "2.5", "--debug"],
        ):
            cull_lights.main()

        call_kwargs = mock_cull.call_args[1]
        assert call_kwargs["debug"] is True

    @patch("ap_cull_lights.cull_lights.cull_lights")
    def test_main_with_dryrun(self, mock_cull):
        """Test main with --dryrun flag."""
        with patch(
            "sys.argv",
            ["cull_lights.py", "/source", "/reject", "--max-hfr", "2.5", "--dryrun"],
        ):
            cull_lights.main()

        call_kwargs = mock_cull.call_args[1]
        assert call_kwargs["dryrun"] is True

    def test_main_no_thresholds_error(self):
        """Test that main raises error when no thresholds specified."""
        with patch("sys.argv", ["cull_lights.py", "/source", "/reject"]):
            with pytest.raises(SystemExit):
                cull_lights.main()
